# -*- coding: utf-8 -*-
"""Gen_AI_Assignmnet_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EYW80gu16JPTaYVuAsWN5YJxWjMUsLmV
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from tqdm import tqdm
import time
import warnings
warnings.filterwarnings('ignore')

# Set random seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"CUDA Version: {torch.version.cuda}")

class ConfigurableCNN(nn.Module):
    def __init__(self,
                 num_conv_layers=3,
                 use_batch_norm=True,
                 use_dropout=True,
                 activation='relu',
                 dropout_rate=0.5):
        super(ConfigurableCNN, self).__init__()

        self.num_conv_layers = num_conv_layers
        self.activation_fn = self._get_activation(activation)

        # Build convolutional layers
        layers = []
        in_channels = 3

        for i in range(num_conv_layers):
            out_channels = 32 * (2 ** min(i, 3))  # 32, 64, 128, 256, then cap

            layers.append(nn.Conv2d(in_channels, out_channels,
                                   kernel_size=3, padding=1))

            if use_batch_norm:
                layers.append(nn.BatchNorm2d(out_channels))

            layers.append(self._get_activation(activation))
            layers.append(nn.MaxPool2d(2, 2))

            if use_dropout:
                layers.append(nn.Dropout2d(dropout_rate * 0.5))  # Lighter dropout for conv

            in_channels = out_channels

        self.conv_layers = nn.Sequential(*layers)

        # Calculate the size after conv layers
        # CIFAR-10 images are 32x32
        final_size = 32 // (2 ** num_conv_layers)
        self.flatten_size = out_channels * final_size * final_size

        # Fully connected layers
        fc_layers = [
            nn.Linear(self.flatten_size, 512),
            self._get_activation(activation)
        ]

        if use_dropout:
            fc_layers.append(nn.Dropout(dropout_rate))

        fc_layers.extend([
            nn.Linear(512, 128),
            self._get_activation(activation)
        ])

        if use_dropout:
            fc_layers.append(nn.Dropout(dropout_rate * 0.5))

        fc_layers.append(nn.Linear(128, 10))

        self.fc_layers = nn.Sequential(*fc_layers)

    def _get_activation(self, name):
        activations = {
            'relu': nn.ReLU(),
            'leaky_relu': nn.LeakyReLU(0.1),
            'elu': nn.ELU(),
            'tanh': nn.Tanh(),
            'silu': nn.SiLU()
        }
        return activations.get(name, nn.ReLU())

    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layers(x)
        return x

# Test the model
print("Testing model instantiation...")
test_model = ConfigurableCNN(num_conv_layers=3, use_batch_norm=True,
                            use_dropout=True, activation='relu')
test_input = torch.randn(2, 3, 32, 32)
test_output = test_model(test_input)
print(f"Input shape: {test_input.shape}")
print(f"Output shape: {test_output.shape}")
print(f"Total parameters: {sum(p.numel() for p in test_model.parameters()):,}")
del test_model, test_input, test_output

def load_cifar10(batch_size=128):
    """Load and preprocess CIFAR-10 dataset"""

    # Data augmentation for training
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465),
                           (0.2023, 0.1994, 0.2010))
    ])

    # No augmentation for validation
    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465),
                           (0.2023, 0.1994, 0.2010))
    ])

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                           download=True, transform=transform_train)

    testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                          download=True, transform=transform_test)

    trainloader = DataLoader(trainset, batch_size=batch_size,
                            shuffle=True, num_workers=2)
    testloader = DataLoader(testset, batch_size=batch_size,
                           shuffle=False, num_workers=2)

    return trainloader, testloader

# Load the data
print("Loading CIFAR-10 dataset...")
trainloader, testloader = load_cifar10(batch_size=128)
print(f"Training batches: {len(trainloader)}")
print(f"Testing batches: {len(testloader)}")
print(f"Total training images: {len(trainloader.dataset)}")
print(f"Total testing images: {len(testloader.dataset)}")

# Visualize sample images
classes = ('plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')

def imshow(img):
    img = img / 2 + 0.5  # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.axis('off')

# Get some random training images
dataiter = iter(trainloader)
images, labels = next(dataiter)

# Show images
fig, axes = plt.subplots(2, 8, figsize=(16, 4))
for idx, ax in enumerate(axes.flat):
    if idx < 16:
        img = images[idx] / 2 + 0.5  # unnormalize
        npimg = img.numpy()
        ax.imshow(np.transpose(npimg, (1, 2, 0)))
        ax.set_title(classes[labels[idx]], fontsize=10)
        ax.axis('off')

plt.tight_layout()
plt.suptitle('Sample CIFAR-10 Images', y=1.02, fontsize=14)
plt.show()

def train_epoch(model, trainloader, criterion, optimizer, device):
    """Train for one epoch"""
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    pbar = tqdm(trainloader, desc='Training', leave=False)
    for inputs, labels in pbar:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

        pbar.set_postfix({'loss': f'{running_loss/len(trainloader):.4f}',
                         'acc': f'{100.*correct/total:.2f}%'})

    return running_loss / len(trainloader), 100. * correct / total


def validate(model, testloader, criterion, device):
    """Validate the model"""
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        pbar = tqdm(testloader, desc='Validation', leave=False)
        for inputs, labels in pbar:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            pbar.set_postfix({'loss': f'{running_loss/len(testloader):.4f}',
                             'acc': f'{100.*correct/total:.2f}%'})

    return running_loss / len(testloader), 100. * correct / total

print("Training and validation functions defined successfully!")

def run_experiment(config, trainloader, testloader, num_epochs=50):
    """Run a single experiment configuration"""

    print(f"\n{'='*60}")
    print(f"Running: {config['name']}")
    print(f"{'='*60}")
    print(f"Config: Conv Layers={config['num_conv_layers']}, "
          f"BatchNorm={config['use_batch_norm']}, "
          f"Dropout={config['use_dropout']}, "
          f"Activation={config['activation']}")

    # Create model
    model = ConfigurableCNN(
        num_conv_layers=config['num_conv_layers'],
        use_batch_norm=config['use_batch_norm'],
        use_dropout=config['use_dropout'],
        activation=config['activation'],
        dropout_rate=config.get('dropout_rate', 0.5)
    ).to(device)

    # Count parameters
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',
                                                      factor=0.5, patience=5)

    # Training history
    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': []
    }

    best_val_acc = 0.0
    start_time = time.time()

    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch+1}/{num_epochs}")

        train_loss, train_acc = train_epoch(model, trainloader, criterion,
                                           optimizer, device)
        val_loss, val_acc = validate(model, testloader, criterion, device)

        # Update scheduler
        scheduler.step(val_acc)

        # Store history
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)

        print(f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
        print(f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            print(f"✓ New best validation accuracy: {best_val_acc:.2f}%")

    training_time = time.time() - start_time

    results = {
        'name': config['name'],
        'config': config,
        'history': history,
        'best_val_acc': best_val_acc,
        'final_train_acc': history['train_acc'][-1],
        'final_val_acc': history['val_acc'][-1],
        'overfitting_gap': history['train_acc'][-1] - history['val_acc'][-1],
        'total_params': total_params,
        'training_time': training_time
    }

    print(f"\n{'='*60}")
    print(f"Experiment Complete!")
    print(f"Best Val Acc: {best_val_acc:.2f}%")
    print(f"Final Val Acc: {results['final_val_acc']:.2f}%")
    print(f"Overfitting Gap: {results['overfitting_gap']:.2f}%")
    print(f"Training Time: {training_time/60:.1f} minutes")
    print(f"{'='*60}")

    return results

print("Experiment runner function defined successfully!")

experiments = [
    # Baseline
    {
        'name': 'Baseline (No BN/Dropout)',
        'num_conv_layers': 3,
        'use_batch_norm': False,
        'use_dropout': False,
        'activation': 'relu'
    },

    # Batch Normalization & Dropout effects
    {
        'name': 'With BatchNorm Only',
        'num_conv_layers': 3,
        'use_batch_norm': True,
        'use_dropout': False,
        'activation': 'relu'
    },
    {
        'name': 'With Dropout Only',
        'num_conv_layers': 3,
        'use_batch_norm': False,
        'use_dropout': True,
        'activation': 'relu',
        'dropout_rate': 0.5
    },
    {
        'name': 'BatchNorm + Dropout',
        'num_conv_layers': 3,
        'use_batch_norm': True,
        'use_dropout': True,
        'activation': 'relu',
        'dropout_rate': 0.5
    },

    # Layer depth variations
    {
        'name': '2 Conv Layers (Shallow)',
        'num_conv_layers': 2,
        'use_batch_norm': True,
        'use_dropout': True,
        'activation': 'relu'
    },
    {
        'name': '4 Conv Layers (Deep)',
        'num_conv_layers': 4,
        'use_batch_norm': True,
        'use_dropout': True,
        'activation': 'relu'
    },

    # Activation function variations
    {
        'name': 'LeakyReLU',
        'num_conv_layers': 3,
        'use_batch_norm': True,
        'use_dropout': True,
        'activation': 'leaky_relu'
    },
    {
        'name': 'ELU',
        'num_conv_layers': 3,
        'use_batch_norm': True,
        'use_dropout': True,
        'activation': 'elu'
    },
    {
        'name': 'SiLU',
        'num_conv_layers': 3,
        'use_batch_norm': True,
        'use_dropout': True,
        'activation': 'silu'
    }
]

print(f"Defined {len(experiments)} experiments:")
for i, exp in enumerate(experiments, 1):
    print(f"{i}. {exp['name']}")

NUM_EPOCHS = 5  # Change to 10-20 for quick testing

all_results = []

for i, config in enumerate(experiments, 1):
    print(f"\n\n{'#'*70}")
    print(f"# EXPERIMENT {i}/{len(experiments)}")
    print(f"{'#'*70}")

    result = run_experiment(config, trainloader, testloader, num_epochs=NUM_EPOCHS)
    all_results.append(result)

    # Save intermediate results
    torch.save(all_results, 'cifar10_all_results.pth')
    print(f"\n✓ Results saved to cifar10_all_results.pth")

print("\n\n" + "="*70)
print("ALL EXPERIMENTS COMPLETED!")
print("="*70)

def plot_single_experiment(result):
    """Plot training history for a single experiment"""
    history = result['history']

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Loss plot
    ax = axes[0]
    epochs = range(1, len(history['train_loss']) + 1)
    ax.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)
    ax.plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)
    ax.set_xlabel('Epoch', fontsize=12)
    ax.set_ylabel('Loss', fontsize=12)
    ax.set_title(f"{result['name']} - Loss", fontsize=14)
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)

    # Accuracy plot
    ax = axes[1]
    ax.plot(epochs, history['train_acc'], 'b-', label='Train Acc', linewidth=2)
    ax.plot(epochs, history['val_acc'], 'r-', label='Val Acc', linewidth=2)
    ax.set_xlabel('Epoch', fontsize=12)
    ax.set_ylabel('Accuracy (%)', fontsize=12)
    ax.set_title(f"{result['name']} - Accuracy", fontsize=14)
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()


def plot_experiment_comparison(all_results):
    """Plot comparison of all experiments"""

    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # Plot 1: Validation Accuracy over epochs
    ax = axes[0, 0]
    for result in all_results:
        ax.plot(result['history']['val_acc'],
               label=result['name'], linewidth=2, alpha=0.8)
    ax.set_xlabel('Epoch', fontsize=12)
    ax.set_ylabel('Validation Accuracy (%)', fontsize=12)
    ax.set_title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')
    ax.legend(fontsize=9, loc='lower right')
    ax.grid(True, alpha=0.3)

    # Plot 2: Training vs Validation Accuracy (final)
    ax = axes[0, 1]
    names = [r['name'] for r in all_results]
    train_accs = [r['final_train_acc'] for r in all_results]
    val_accs = [r['final_val_acc'] for r in all_results]

    x = np.arange(len(names))
    width = 0.35
    ax.bar(x - width/2, train_accs, width, label='Train', alpha=0.8, color='skyblue')
    ax.bar(x + width/2, val_accs, width, label='Validation', alpha=0.8, color='coral')
    ax.set_ylabel('Accuracy (%)', fontsize=12)
    ax.set_title('Final Train vs Validation Accuracy', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(names, rotation=45, ha='right', fontsize=9)
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3, axis='y')

    # Plot 3: Overfitting Gap
    ax = axes[1, 0]
    gaps = [r['overfitting_gap'] for r in all_results]
    colors = ['green' if g < 10 else 'orange' if g < 15 else 'red' for g in gaps]
    bars = ax.barh(names, gaps, color=colors, alpha=0.7)
    ax.set_xlabel('Overfitting Gap (Train - Val %)', fontsize=12)
    ax.set_title('Overfitting Analysis', fontsize=14, fontweight='bold')
    ax.axvline(x=10, color='red', linestyle='--', alpha=0.5, linewidth=2, label='10% threshold')
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3, axis='x')

    # Add value labels
    for i, (bar, gap) in enumerate(zip(bars, gaps)):
        ax.text(gap + 0.5, i, f'{gap:.1f}%', va='center', fontsize=9)

    # Plot 4: Best Validation Accuracy
    ax = axes[1, 1]
    best_accs = [r['best_val_acc'] for r in all_results]
    colors_acc = ['green' if acc >= 80 else 'orange' if acc >= 75 else 'red'
                  for acc in best_accs]
    bars = ax.barh(names, best_accs, color=colors_acc, alpha=0.7)
    ax.set_xlabel('Best Validation Accuracy (%)', fontsize=12)
    ax.set_title('Best Validation Accuracy Achieved', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3, axis='x')
    ax.set_xlim([0, 100])

    # Add value labels
    for i, (bar, acc) in enumerate(zip(bars, best_accs)):
        ax.text(acc + 1, i, f'{acc:.2f}%', va='center', fontsize=9)

    plt.tight_layout()
    plt.savefig('cifar10_experiment_comparison.png', dpi=300, bbox_inches='tight')
    print("✓ Saved: cifar10_experiment_comparison.png")
    plt.show()


def create_results_table(all_results):
    """Create a summary table of all results"""

    data = []
    for r in all_results:
        data.append({
            'Experiment': r['name'],
            'Conv Layers': r['config']['num_conv_layers'],
            'BatchNorm': 'Yes' if r['config']['use_batch_norm'] else 'No',
            'Dropout': 'Yes' if r['config']['use_dropout'] else 'No',
            'Activation': r['config']['activation'],
            'Parameters': f"{r['total_params']:,}",
            'Best Val Acc': f"{r['best_val_acc']:.2f}%",
            'Final Val Acc': f"{r['final_val_acc']:.2f}%",
            'Overfit Gap': f"{r['overfitting_gap']:.2f}%",
            'Training Time': f"{r['training_time']/60:.1f} min"
        })

    df = pd.DataFrame(data)

    # Style the dataframe
    styled_df = df.style.set_properties(**{
        'text-align': 'left',
        'font-size': '11pt',
    }).set_table_styles([
        {'selector': 'th', 'props': [('font-size', '12pt'), ('font-weight', 'bold'),
                                     ('text-align', 'center'), ('background-color', '#f0f0f0')]}
    ])

    print("\n" + "="*120)
    print("EXPERIMENT RESULTS SUMMARY")
    print("="*120)
    print(df.to_string(index=False))
    print("="*120)

    df.to_csv('cifar10_results.csv', index=False)
    print("\n✓ Saved: cifar10_results.csv")

    return df

print("Visualization functions defined successfully!")

# Plot comparison of all experiments
plot_experiment_comparison(all_results)

# Create summary table
results_df = create_results_table(all_results)

# Display the best performing model
best_result = max(all_results, key=lambda x: x['best_val_acc'])
print(f"\n{'='*70}")
print("BEST PERFORMING MODEL:")
print(f"{'='*70}")
print(f"Name: {best_result['name']}")
print(f"Best Validation Accuracy: {best_result['best_val_acc']:.2f}%")
print(f"Configuration:")
for key, value in best_result['config'].items():
    if key != 'name':
        print(f"  - {key}: {value}")
print(f"{'='*70}")

print("\n" + "="*70)
print("KEY FINDINGS FOR YOUR PRESENTATION:")
print("="*70)

# Find best configurations for each aspect
bn_experiments = [r for r in all_results if 'BatchNorm' in r['name'] or 'Baseline' in r['name']]
if len(bn_experiments) >= 2:
    best_bn = max(bn_experiments, key=lambda x: x['best_val_acc'])
    print(f"\n1. BatchNorm/Dropout Effect:")
    print(f"   Best: {best_bn['name']} - {best_bn['best_val_acc']:.2f}% val acc")

layer_experiments = [r for r in all_results if 'Conv Layers' in r['name']]
if layer_experiments:
    best_layers = max(layer_experiments, key=lambda x: x['best_val_acc'])
    print(f"\n2. Layer Depth Effect:")
    print(f"   Best: {best_layers['name']} - {best_layers['best_val_acc']:.2f}% val acc")

activation_experiments = [r for r in all_results if r['config']['activation'] != 'relu'
                          or 'BatchNorm + Dropout' in r['name']]
if activation_experiments:
    print(f"\n3. Activation Function Comparison:")
    for r in activation_experiments:
        if 'LeakyReLU' in r['name'] or 'ELU' in r['name'] or 'SiLU' in r['name']:
            print(f"   {r['config']['activation']}: {r['best_val_acc']:.2f}% val acc")

# Overfitting analysis
print(f"\n4. Overfitting Analysis:")
for r in all_results:
    if r['overfitting_gap'] < 10:
        print(f"   ✓ {r['name']}: Gap = {r['overfitting_gap']:.2f}% (Good generalization)")
    elif r['overfitting_gap'] > 15:
        print(f"   ✗ {r['name']}: Gap = {r['overfitting_gap']:.2f}% (Overfitting)")

print("\n" + "="*70)